{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分完成\n",
      "训练集大小: 998\n",
      "测试集大小: 250\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# 1. 加载数据\n",
    "dataX = np.loadtxt('dataset1/dataX.txt')\n",
    "dataY = np.loadtxt('dataset1/dataY.txt')\n",
    "dataZ = np.loadtxt('dataset1/dataZ.txt')\n",
    "dataLabels = np.loadtxt('dataset1/dataLabel.txt')  # 假设每一行有两列\n",
    "\n",
    "# 2. 数据预处理：合并 x, y, z 方向的数据\n",
    "data = np.column_stack((dataX, dataY, dataZ))\n",
    "\n",
    "# 将标签分为两个部分：defect 标签和 severity 标签\n",
    "labels_defect = dataLabels[:, 0].astype(int)  # 道路缺陷标签\n",
    "labels_severity = dataLabels[:, 1].astype(int)  # 严重程度标签\n",
    "\n",
    "# 3. 时域特征提取函数\n",
    "def extract_features(data):\n",
    "    features = []\n",
    "    for group in data:\n",
    "        feature = []\n",
    "        feature.append(np.mean(group))         # 均值\n",
    "        feature.append(np.std(group))          # 标准差\n",
    "        feature.append(np.min(group))          # 最小值\n",
    "        feature.append(np.max(group))          # 最大值\n",
    "        feature.append(np.var(group))          # 方差\n",
    "        feature.append(np.sqrt(np.mean(group**2)))  # 均方根\n",
    "        feature.append(kurtosis(group))        # 峰度\n",
    "        feature.append(skew(group))            # 偏度\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# 提取 x, y, z 三个方向的时域特征\n",
    "features_X = extract_features(dataX)\n",
    "features_Y = extract_features(dataY)\n",
    "features_Z = extract_features(dataZ)\n",
    "\n",
    "# 将特征合并\n",
    "data_features = np.column_stack((features_X, features_Y, features_Z))\n",
    "\n",
    "# 4. 划分数据集\n",
    "X_train, X_test, y_train_defect, y_test_defect, y_train_severity, y_test_severity = train_test_split(\n",
    "    data_features, labels_defect, labels_severity, test_size=0.2, stratify=labels_defect, random_state=42\n",
    ")\n",
    "\n",
    "# 5. 创建 PyTorch 数据加载器\n",
    "# 转换为 PyTorch 张量\n",
    "train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "train_labels_defect_tensor = torch.tensor(y_train_defect, dtype=torch.long)\n",
    "test_labels_defect_tensor = torch.tensor(y_test_defect, dtype=torch.long)\n",
    "\n",
    "train_labels_severity_tensor = torch.tensor(y_train_severity, dtype=torch.long)\n",
    "test_labels_severity_tensor = torch.tensor(y_test_severity, dtype=torch.long)\n",
    "\n",
    "# 创建 TensorDataset 和 DataLoader\n",
    "train_dataset = TensorDataset(train_tensor, train_labels_defect_tensor, train_labels_severity_tensor)\n",
    "test_dataset = TensorDataset(test_tensor, test_labels_defect_tensor, test_labels_severity_tensor)\n",
    "batch_size = 1024  # 你可以在这里修改批大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"数据集划分完成\")\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-09-17 16:15:00,143]\u001b[0m Finished trial#0 resulted in value: -0.8260000000000001. Current best value is -0.8260000000000001 with parameters: {'lr': 0.007904286522713692, 'batch_size': 32, 'dropout_rate': 0.3777513159299868, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:00,839]\u001b[0m Finished trial#1 resulted in value: -0.252. Current best value is -0.8260000000000001 with parameters: {'lr': 0.007904286522713692, 'batch_size': 32, 'dropout_rate': 0.3777513159299868, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:02,276]\u001b[0m Finished trial#2 resulted in value: -0.6859999999999999. Current best value is -0.8260000000000001 with parameters: {'lr': 0.007904286522713692, 'batch_size': 32, 'dropout_rate': 0.3777513159299868, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:02,753]\u001b[0m Finished trial#3 resulted in value: -0.602. Current best value is -0.8260000000000001 with parameters: {'lr': 0.007904286522713692, 'batch_size': 32, 'dropout_rate': 0.3777513159299868, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:04,242]\u001b[0m Finished trial#4 resulted in value: -0.8420000000000001. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:05,106]\u001b[0m Finished trial#5 resulted in value: -0.8260000000000001. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:05,733]\u001b[0m Finished trial#6 resulted in value: -0.78. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:06,731]\u001b[0m Finished trial#7 resulted in value: -0.78. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:07,173]\u001b[0m Finished trial#8 resulted in value: -0.786. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:07,630]\u001b[0m Finished trial#9 resulted in value: -0.8360000000000001. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:09,030]\u001b[0m Finished trial#10 resulted in value: -0.798. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:09,508]\u001b[0m Finished trial#11 resulted in value: -0.8380000000000001. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:11,112]\u001b[0m Finished trial#12 resulted in value: -0.784. Current best value is -0.8420000000000001 with parameters: {'lr': 0.00039742371714519343, 'batch_size': 16, 'dropout_rate': 0.48662922734232206, 'hidden_dim': 32}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:12,679]\u001b[0m Finished trial#13 resulted in value: -0.846. Current best value is -0.846 with parameters: {'lr': 0.0007854502358145142, 'batch_size': 16, 'dropout_rate': 0.10302841676259389, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:14,065]\u001b[0m Finished trial#14 resulted in value: -0.8440000000000001. Current best value is -0.846 with parameters: {'lr': 0.0007854502358145142, 'batch_size': 16, 'dropout_rate': 0.10302841676259389, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:15,897]\u001b[0m Finished trial#15 resulted in value: -0.8440000000000001. Current best value is -0.846 with parameters: {'lr': 0.0007854502358145142, 'batch_size': 16, 'dropout_rate': 0.10302841676259389, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:17,492]\u001b[0m Finished trial#16 resulted in value: -0.856. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:19,112]\u001b[0m Finished trial#17 resulted in value: -0.8500000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:20,756]\u001b[0m Finished trial#18 resulted in value: -0.8220000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:21,440]\u001b[0m Finished trial#19 resulted in value: -0.8460000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:23,281]\u001b[0m Finished trial#20 resulted in value: -0.8360000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:23,967]\u001b[0m Finished trial#21 resulted in value: -0.81. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:24,674]\u001b[0m Finished trial#22 resulted in value: -0.8400000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:25,325]\u001b[0m Finished trial#23 resulted in value: -0.8420000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:26,000]\u001b[0m Finished trial#24 resulted in value: -0.812. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:27,557]\u001b[0m Finished trial#25 resulted in value: -0.8480000000000001. Current best value is -0.856 with parameters: {'lr': 0.0010898185671361156, 'batch_size': 16, 'dropout_rate': 0.14939146290164623, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:29,049]\u001b[0m Finished trial#26 resulted in value: -0.862. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:30,526]\u001b[0m Finished trial#27 resulted in value: -0.764. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:32,206]\u001b[0m Finished trial#28 resulted in value: -0.844. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:33,143]\u001b[0m Finished trial#29 resulted in value: -0.8240000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:35,082]\u001b[0m Finished trial#30 resulted in value: -0.8160000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:36,629]\u001b[0m Finished trial#31 resulted in value: -0.856. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:38,131]\u001b[0m Finished trial#32 resulted in value: -0.798. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:39,857]\u001b[0m Finished trial#33 resulted in value: -0.8340000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:41,450]\u001b[0m Finished trial#34 resulted in value: -0.846. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:42,924]\u001b[0m Finished trial#35 resulted in value: -0.81. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:44,412]\u001b[0m Finished trial#36 resulted in value: -0.8420000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:45,871]\u001b[0m Finished trial#37 resulted in value: -0.786. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:46,866]\u001b[0m Finished trial#38 resulted in value: -0.8200000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:48,344]\u001b[0m Finished trial#39 resulted in value: -0.8. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:49,949]\u001b[0m Finished trial#40 resulted in value: -0.8160000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:51,526]\u001b[0m Finished trial#41 resulted in value: -0.8440000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:53,013]\u001b[0m Finished trial#42 resulted in value: -0.8380000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:54,506]\u001b[0m Finished trial#43 resulted in value: -0.8320000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:55,079]\u001b[0m Finished trial#44 resulted in value: -0.8360000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:56,614]\u001b[0m Finished trial#45 resulted in value: -0.794. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:58,106]\u001b[0m Finished trial#46 resulted in value: -0.8300000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:15:59,014]\u001b[0m Finished trial#47 resulted in value: -0.848. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:16:00,751]\u001b[0m Finished trial#48 resulted in value: -0.85. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n",
      "\u001b[32m[I 2024-09-17 16:16:01,182]\u001b[0m Finished trial#49 resulted in value: -0.8480000000000001. Current best value is -0.862 with parameters: {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'lr': 0.0006871684713341972, 'batch_size': 16, 'dropout_rate': 0.10354175985501725, 'hidden_dim': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.81"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# 1. 加载数据\n",
    "dataX = np.loadtxt('dataset1/dataX.txt')\n",
    "dataY = np.loadtxt('dataset1/dataY.txt')\n",
    "dataZ = np.loadtxt('dataset1/dataZ.txt')\n",
    "dataLabels = np.loadtxt('dataset1/dataLabel.txt')  # 假设每一行有两列\n",
    "\n",
    "# 将标签分为两个部分：defect 标签和 severity 标签\n",
    "labels_defect = dataLabels[:, 0].astype(int)  # 道路缺陷标签\n",
    "labels_severity = dataLabels[:, 1].astype(int)  # 严重程度标签\n",
    "\n",
    "# 2. 时域特征提取函数\n",
    "def extract_time_features(data):\n",
    "    features = []\n",
    "    for group in data:\n",
    "        feature = []\n",
    "        feature.append(np.mean(group))         # 均值\n",
    "        feature.append(np.std(group))          # 标准差\n",
    "        feature.append(np.min(group))          # 最小值\n",
    "        feature.append(np.max(group))          # 最大值\n",
    "        feature.append(np.var(group))          # 方差\n",
    "        feature.append(np.sqrt(np.mean(group**2)))  # 均方根\n",
    "        feature.append(kurtosis(group))        # 峰度\n",
    "        feature.append(skew(group))            # 偏度\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# 3. 频域特征提取函数\n",
    "def extract_frequency_features(data):\n",
    "    features = []\n",
    "    for group in data:\n",
    "        fft_vals = np.fft.fft(group)\n",
    "        amplitude_spectrum = np.abs(fft_vals)\n",
    "        phase_spectrum = np.angle(fft_vals)\n",
    "\n",
    "        # 计算频域特征\n",
    "        feature = []\n",
    "        feature.append(np.mean(amplitude_spectrum))        # 幅度谱均值\n",
    "        feature.append(np.std(amplitude_spectrum))         # 幅度谱标准差\n",
    "        feature.append(np.mean(phase_spectrum))            # 相位谱均值\n",
    "        feature.append(np.std(phase_spectrum))             # 相位谱标准差\n",
    "        feature.append(np.mean(amplitude_spectrum[:len(amplitude_spectrum)//2]))  # 低频部分均值\n",
    "        feature.append(np.mean(amplitude_spectrum[len(amplitude_spectrum)//2:]))  # 高频部分均值\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# 提取 x, y, z 三个方向的时域特征和频域特征\n",
    "time_features_X = extract_time_features(dataX)\n",
    "time_features_Y = extract_time_features(dataY)\n",
    "time_features_Z = extract_time_features(dataZ)\n",
    "\n",
    "freq_features_X = extract_frequency_features(dataX)\n",
    "freq_features_Y = extract_frequency_features(dataY)\n",
    "freq_features_Z = extract_frequency_features(dataZ)\n",
    "\n",
    "# 将时域特征和频域特征合并\n",
    "features_X = np.column_stack((time_features_X, freq_features_X))\n",
    "features_Y = np.column_stack((time_features_Y, freq_features_Y))\n",
    "features_Z = np.column_stack((time_features_Z, freq_features_Z))\n",
    "\n",
    "# 将特征合并\n",
    "data_features = np.column_stack((features_X, features_Y, features_Z))\n",
    "\n",
    "# 4. 划分数据集\n",
    "X_train, X_test, y_train_defect, y_test_defect, y_train_severity, y_test_severity = train_test_split(\n",
    "    data_features, labels_defect, labels_severity, test_size=0.2, stratify=labels_defect, random_state=42\n",
    ")\n",
    "\n",
    "# 5. 定义模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout_rate):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_defect = nn.Linear(hidden_dim, 3)  # 道路缺陷分类输出 (假设是 3 类)\n",
    "        self.fc_severity = nn.Linear(hidden_dim, 4)  # 严重程度分类输出 (假设是 4 类)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        defect_output = self.fc_defect(x)\n",
    "        severity_output = self.fc_severity(x)\n",
    "        return defect_output, severity_output\n",
    "\n",
    "# 6. 定义训练和测试过程\n",
    "def train_and_evaluate_model(learning_rate, batch_size, dropout_rate, hidden_dim):\n",
    "    # 创建数据加载器\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                  torch.tensor(y_train_defect, dtype=torch.long),\n",
    "                                  torch.tensor(y_train_severity, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                torch.tensor(y_test_defect, dtype=torch.long),\n",
    "                                torch.tensor(y_test_severity, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # 定义模型\n",
    "    model = SimpleNN(input_dim=X_train.shape[1], hidden_dim=hidden_dim, dropout_rate=dropout_rate)\n",
    "    \n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 训练模型\n",
    "    num_epochs = 20\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, defect_labels, severity_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            defect_preds, severity_preds = model(inputs)\n",
    "            loss_defect = criterion(defect_preds, defect_labels)\n",
    "            loss_severity = criterion(severity_preds, severity_labels)\n",
    "            loss = loss_defect + loss_severity\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    # 在验证集上评估模型\n",
    "    model.eval()\n",
    "    all_defect_labels = []\n",
    "    all_defect_preds = []\n",
    "    all_severity_labels = []\n",
    "    all_severity_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, defect_labels, severity_labels in val_loader:\n",
    "            defect_preds, severity_preds = model(inputs)\n",
    "            _, predicted_defects = torch.max(defect_preds, 1)\n",
    "            _, predicted_severities = torch.max(severity_preds, 1)\n",
    "\n",
    "            all_defect_labels.extend(defect_labels.cpu().numpy())\n",
    "            all_defect_preds.extend(predicted_defects.cpu().numpy())\n",
    "            all_severity_labels.extend(severity_labels.cpu().numpy())\n",
    "            all_severity_preds.extend(predicted_severities.cpu().numpy())\n",
    "\n",
    "    # 计算验证集上的准确率\n",
    "    accuracy_defect = accuracy_score(all_defect_labels, all_defect_preds)\n",
    "    accuracy_severity = accuracy_score(all_severity_labels, all_severity_preds)\n",
    "\n",
    "    avg_accuracy = (accuracy_defect + accuracy_severity) / 2\n",
    "    return -avg_accuracy\n",
    "\n",
    "# 7. 使用 Optuna 进行超参数优化\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [32, 64, 128])\n",
    "\n",
    "    return train_and_evaluate_model(learning_rate, batch_size, dropout_rate, hidden_dim)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)  # 进行 50 次试验\n",
    "\n",
    "# 输出最佳超参数\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "\n",
    "# 使用最佳超参数重新训练模型\n",
    "best_params = study.best_params\n",
    "train_and_evaluate_model(best_params['lr'], best_params['batch_size'], best_params['dropout_rate'], best_params['hidden_dim'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
