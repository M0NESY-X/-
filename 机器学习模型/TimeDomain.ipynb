{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from siml.sk_utils import *\n",
    "from siml.signal_analysis_utils import *\n",
    "import numpy as np\n",
    "import math\n",
    "import pylab as pl\n",
    "import scipy.signal as signal\n",
    "import pywt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:06.565090Z",
     "start_time": "2020-07-07T14:38:06.561109Z"
    }
   },
   "outputs": [],
   "source": [
    "typeDescription = {\n",
    "    0: 'normal',\n",
    "    1: 'pothole',\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def readFile(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:07.221336Z",
     "start_time": "2020-07-07T14:38:06.567083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集： (1248, 50)\n",
      "[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
      "{'pothole': 508, 'normal': 740}\n"
     ]
    }
   ],
   "source": [
    "folderPath = 'dataset1/'\n",
    "dataFile = ['dataX.txt', 'dataY.txt', 'dataZ.txt']\n",
    "labelFile = ['dataLabel.txt']\n",
    "\n",
    "signals = []\n",
    "for file in dataFile:\n",
    "    dataPath = folderPath+file\n",
    "    signals.append(np.loadtxt(dataPath))\n",
    "signals = np.transpose(np.array(signals), (1, 2, 0))\n",
    "print('数据集：', signals[:,:,0].shape)\n",
    "\n",
    "labelFilePath = folderPath+labelFile[0]\n",
    "dataLabel = np.loadtxt(labelFilePath)\n",
    "anomalyType = list(dataLabel[:, 0])\n",
    "print(anomalyType)\n",
    "dic = {}\n",
    "temp = Counter(anomalyType)\n",
    "for key in temp.keys():\n",
    "    dic[typeDescription[key]] = temp[key]\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 时域特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:07.235296Z",
     "start_time": "2020-07-07T14:38:07.223330Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    # print(counter_values)\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    # print(probabilities)\n",
    "    entropy = scipy.stats.entropy(probabilities)\n",
    "    entropy_list = []\n",
    "    i = 0\n",
    "    while i < 9:\n",
    "        i = i + 1\n",
    "        entropy_list.append(entropy)\n",
    "        \n",
    "    return entropy_list\n",
    "\n",
    "def calculate_fourierCoefficient(x):\n",
    "    N = len(x)\n",
    "    real = [0]*10\n",
    "    imag = [0]*10\n",
    "    result = [0]*10\n",
    "    n =0\n",
    "    i = 0\n",
    "    k = 0\n",
    "    while k < 10:\n",
    "        while n < N:\n",
    "            real[k] = real[k] + x[n] * np.cos(2*np.pi*(k+40)*n/N) \n",
    "            imag[k] = imag[k] - x[n] * np.sin(2*np.pi*(k+40)*n/N) \n",
    "            n = n + 1\n",
    "        n = 0\n",
    "        k = k + 1\n",
    "    while i < 10:\n",
    "        result[i] = np.sqrt(real[i]*real[i]+imag[i]*imag[i])\n",
    "        i = i + 1\n",
    "    return real\n",
    "\n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    min = np.min(list_values)\n",
    "    max = np.max(list_values)\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms, min, max]\n",
    "\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(\n",
    "        np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings+no_mean_crossings]\n",
    "\n",
    "\n",
    "def get_features(list_values):\n",
    "    entropy_list = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    fourierCoefficient = calculate_fourierCoefficient(list_values)\n",
    "    return statistics + fourierCoefficient\n",
    "\n",
    "\n",
    "def extract_features(dataset):\n",
    "    uci_har_features = []\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []\n",
    "        for signal_comp in range(0, 3):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "            features += get_features(signal)\n",
    "        uci_har_features.append(features)\n",
    "    X = np.array(uci_har_features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:18.579219Z",
     "start_time": "2020-07-07T14:38:07.237289Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1248, 63)\n"
     ]
    }
   ],
   "source": [
    "features = extract_features(signals)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:18.586172Z",
     "start_time": "2020-07-07T14:38:18.580157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(anomalyType)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:18.603098Z",
     "start_time": "2020-07-07T14:38:18.588137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04168651, -0.0106496 ,  0.00762513, ...,  0.20147906,\n",
       "         0.03975483,  0.03045766],\n",
       "       [-0.04671516, -0.01143882,  0.00878131, ..., -0.07826772,\n",
       "         0.05390477,  0.00931587],\n",
       "       [-0.03249816, -0.01057153,  0.0114071 , ..., -0.04529363,\n",
       "        -0.06726094, -0.02124565],\n",
       "       ...,\n",
       "       [-0.02737561, -0.00513955,  0.00744782, ..., -0.18308674,\n",
       "         0.11055013,  0.03821252],\n",
       "       [-0.02480815, -0.00921395,  0.0100039 , ...,  0.19214241,\n",
       "         0.15870465,  0.06861833],\n",
       "       [-0.02332248, -0.01483977,  0.01337723, ..., -0.24813904,\n",
       "         0.01066694, -0.01021894]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(features)\n",
    "Normalizer().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:18.611075Z",
     "start_time": "2020-07-07T14:38:18.606093Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomize(features, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_features = features[permutation, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_features, shuffled_labels\n",
    "\n",
    "iteration = 100\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:38:32.561864Z",
     "start_time": "2020-07-07T14:38:18.613069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "Accuracy on training set is : 0.8687285223367688\n",
      "Accuracy on test set is : 0.8554133333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.862     0.900     0.881     22286\n",
      "         1.0      0.844     0.790     0.816     15214\n",
      "\n",
      "    accuracy                          0.855     37500\n",
      "   macro avg      0.853     0.845     0.848     37500\n",
      "weighted avg      0.855     0.855     0.855     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Logistic Regression\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Classifier using cross validation\n",
    "\n",
    "def svm_cross_validation(train_x, train_y):\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    model = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "    param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid, n_jobs = 8, verbose=1)\n",
    "\n",
    "    grid_search.fit(train_x, train_y)\n",
    "\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "    for para, val in list(best_parameters.items()):\n",
    "\n",
    "        print(para, val)\n",
    "\n",
    "    model = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True)\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:39:01.787000Z",
     "start_time": "2020-07-07T14:38:32.562860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Accuracy on training set is : 0.88139747995418\n",
      "Accuracy on test set is : 0.7393866666666665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.732     0.881     0.800     22160\n",
      "         1.0      0.757     0.535     0.627     15340\n",
      "\n",
      "    accuracy                          0.739     37500\n",
      "   macro avg      0.745     0.708     0.713     37500\n",
      "weighted avg      0.742     0.739     0.729     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=5)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Support Vector Machine\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:40:59.318059Z",
     "start_time": "2020-07-07T14:39:01.787989Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Accuracy on training set is : 1.0\n",
      "Accuracy on test set is : 0.81104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.814     0.884     0.848     22328\n",
      "         1.0      0.805     0.703     0.751     15172\n",
      "\n",
      "    accuracy                          0.811     37500\n",
      "   macro avg      0.810     0.794     0.799     37500\n",
      "weighted avg      0.811     0.811     0.809     37500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跨数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:51:52.930774Z",
     "start_time": "2020-07-07T14:51:38.616598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Reg\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.868     0.868     0.868     10831\n",
      "         1.0      0.810     0.811     0.810      7534\n",
      "\n",
      "    accuracy                          0.844     18365\n",
      "   macro avg      0.839     0.839     0.839     18365\n",
      "weighted avg      0.844     0.844     0.844     18365\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.823     0.949     0.882     11340\n",
      "         1.0      0.905     0.703     0.791      7795\n",
      "\n",
      "    accuracy                          0.849     19135\n",
      "   macro avg      0.864     0.826     0.837     19135\n",
      "weighted avg      0.856     0.849     0.845     19135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of Logistic Reg\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:52:09.663054Z",
     "start_time": "2020-07-07T14:51:52.932741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.838     0.884     0.860     10956\n",
      "         1.0      0.816     0.751     0.782      7520\n",
      "\n",
      "    accuracy                          0.830     18476\n",
      "   macro avg      0.827     0.818     0.821     18476\n",
      "weighted avg      0.829     0.830     0.829     18476\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.786     0.922     0.848     11305\n",
      "         1.0      0.847     0.631     0.724      7719\n",
      "\n",
      "    accuracy                          0.804     19024\n",
      "   macro avg      0.816     0.777     0.786     19024\n",
      "weighted avg      0.811     0.804     0.798     19024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore=0\n",
    "testingScore_poor, testingScore_bad = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = svm.SVC(C=5)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    \n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "   \n",
    "   \n",
    "\n",
    "print(\"Results of Support Vector Machine\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:54:04.278826Z",
     "start_time": "2020-07-07T14:52:09.664050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.853     0.842     0.848     10693\n",
      "         1.0      0.781     0.795     0.788      7556\n",
      "\n",
      "    accuracy                          0.823     18249\n",
      "   macro avg      0.817     0.819     0.818     18249\n",
      "weighted avg      0.823     0.823     0.823     18249\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.809     0.930     0.866     11388\n",
      "         1.0      0.871     0.682     0.765      7863\n",
      "\n",
      "    accuracy                          0.829     19251\n",
      "   macro avg      0.840     0.806     0.815     19251\n",
      "weighted avg      0.835     0.829     0.825     19251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf =RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "_Feature",
    "builtin_function_or_method",
    "function",
    "instance",
    "module"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
